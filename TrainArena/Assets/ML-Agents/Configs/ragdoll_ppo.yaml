behaviors:
  RagdollAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024 # Reduced to match cube config to prevent timeouts
      buffer_size: 10240 # Reduced to match cube config for better responsiveness
      learning_rate: 3.0e-4 # Standard learning rate
      beta: 0.01 # Slightly higher entropy for exploration (was 0.008)
      epsilon: 0.2 # Standard PPO clipping
      lambd: 0.95 # Standard GAE parameter
      num_epoch: 3 # Reduced from 4 to match cube config (faster training)
    network_settings:
      normalize: true # Essential for ragdoll observations
      hidden_units: 128 # Reduced to match cube config for faster training
      num_layers: 2 # Reduced to match cube config to prevent timeouts
      activation: relu # Explicit activation function
    max_steps: 500000 # Reduced to match cube config for faster iteration
    time_horizon: 500 # Shorter horizon to match cube config and prevent timeouts
    summary_freq: 1000 # Much more frequent summaries like cube config
    keep_checkpoints: 5 # Keep multiple checkpoints
    checkpoint_interval: 50000 # Much more frequent checkpoints like cube config
    threaded: true # Enable threading for performance
    reward_signals:
      extrinsic:
        gamma: 0.99 # Standard discount factor
        strength: 1.0
